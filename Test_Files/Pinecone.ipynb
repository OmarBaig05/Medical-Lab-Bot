{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from pinecone import Pinecone\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "dotenv.load_dotenv(\".env\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.data.index.Index at 0x16eff20b410>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"medical-data\"\n",
    "# index_name = \"medicalbot-vdb\"\n",
    "index = pc.Index(index_name)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pinecone import ServerlessSpec\n",
    "\n",
    "# pc.create_index(\n",
    "#     name=\"medical-data\",\n",
    "#     dimension=768,\n",
    "#     metric=\"cosine\",\n",
    "#     spec=ServerlessSpec(\n",
    "#         cloud=\"aws\",\n",
    "#         region=\"us-east-1\"\n",
    "#     ),\n",
    "#     deletion_protection=\"disabled\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def upsert_data_to_pinecone(df):\n",
    "    # Ensure the \"tokens\" column is in the correct format (list of floats)\n",
    "    df[\"tokens\"] = df[\"tokens\"].apply(eval)  # Convert string representation of list to actual list\n",
    "    print(\"1: \",len(df))\n",
    "    # Prepare data for upserting into Pinecone\n",
    "    df = df.fillna(\"\")  # Replace NaN with an empty string\n",
    "    print(\"1: \",len(df))\n",
    "    print(\"Uploading data to Pinecone...\")\n",
    "    data_to_upsert = []\n",
    "    for idx, row in df.iterrows():\n",
    "        metadata = {\n",
    "            \"test_name\": row[\"Test Name\"],\n",
    "            \"source\": row[\"Source\"],\n",
    "            \"url\": row[\"URL\"],\n",
    "            \"text\": row[\"text\"]\n",
    "        }\n",
    "        data_to_upsert.append({\"id\": str(idx), \"values\": row[\"tokens\"], \"metadata\": metadata})\n",
    "\n",
    "    return data_to_upsert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_In_Batches(data_to_upsert, batch_size=100):\n",
    "    # Batch upload\n",
    "    for i in range(0, len(data_to_upsert), batch_size):\n",
    "        batch = data_to_upsert[i:i + batch_size]\n",
    "        index.upsert(vectors=batch)\n",
    "        print(f\"Uploaded batch {i // batch_size + 1} of {len(data_to_upsert) // batch_size + 1}\")\n",
    "        \n",
    "    print(\"Data upload complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your DataFrame\n",
    "df = pd.read_csv(\"../DATA/Embedded_Files/medlinePlus_tokens_325.csv\") \n",
    "df2 = pd.read_csv(\"../DATA/Embedded_Files/testing_com_tokens_325.csv\") \n",
    "df3 = pd.read_csv(\"../DATA/Embedded_Files/files_tokens_325.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16262"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['tokens'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:  2803\n",
      "1:  2803\n",
      "Uploading data to Pinecone...\n",
      "1:  3449\n",
      "1:  3449\n",
      "Uploading data to Pinecone...\n",
      "1:  1148\n",
      "1:  1148\n",
      "Uploading data to Pinecone...\n"
     ]
    }
   ],
   "source": [
    "data_to_upsert = upsert_data_to_pinecone(df)\n",
    "data_to_upsert2 = upsert_data_to_pinecone(df2)\n",
    "data_to_upsert3 = upsert_data_to_pinecone(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2803\n",
      "3449\n",
      "1148\n"
     ]
    }
   ],
   "source": [
    "print(len(data_to_upsert))\n",
    "print(len(data_to_upsert2))\n",
    "print(len(data_to_upsert3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7400"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data_to_upsert = data_to_upsert + data_to_upsert2 + data_to_upsert3\n",
    "len(merged_data_to_upsert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded batch 1 of 75\n",
      "Uploaded batch 2 of 75\n",
      "Uploaded batch 3 of 75\n",
      "Uploaded batch 4 of 75\n",
      "Uploaded batch 5 of 75\n",
      "Uploaded batch 6 of 75\n",
      "Uploaded batch 7 of 75\n",
      "Uploaded batch 8 of 75\n",
      "Uploaded batch 9 of 75\n",
      "Uploaded batch 10 of 75\n",
      "Uploaded batch 11 of 75\n",
      "Uploaded batch 12 of 75\n",
      "Uploaded batch 13 of 75\n",
      "Uploaded batch 14 of 75\n",
      "Uploaded batch 15 of 75\n",
      "Uploaded batch 16 of 75\n",
      "Uploaded batch 17 of 75\n",
      "Uploaded batch 18 of 75\n",
      "Uploaded batch 19 of 75\n",
      "Uploaded batch 20 of 75\n",
      "Uploaded batch 21 of 75\n",
      "Uploaded batch 22 of 75\n",
      "Uploaded batch 23 of 75\n",
      "Uploaded batch 24 of 75\n",
      "Uploaded batch 25 of 75\n",
      "Uploaded batch 26 of 75\n",
      "Uploaded batch 27 of 75\n",
      "Uploaded batch 28 of 75\n",
      "Uploaded batch 29 of 75\n",
      "Uploaded batch 30 of 75\n",
      "Uploaded batch 31 of 75\n",
      "Uploaded batch 32 of 75\n",
      "Uploaded batch 33 of 75\n",
      "Uploaded batch 34 of 75\n",
      "Uploaded batch 35 of 75\n",
      "Uploaded batch 36 of 75\n",
      "Uploaded batch 37 of 75\n",
      "Uploaded batch 38 of 75\n",
      "Uploaded batch 39 of 75\n",
      "Uploaded batch 40 of 75\n",
      "Uploaded batch 41 of 75\n",
      "Uploaded batch 42 of 75\n",
      "Uploaded batch 43 of 75\n",
      "Uploaded batch 44 of 75\n",
      "Uploaded batch 45 of 75\n",
      "Uploaded batch 46 of 75\n",
      "Uploaded batch 47 of 75\n",
      "Uploaded batch 48 of 75\n",
      "Uploaded batch 49 of 75\n",
      "Uploaded batch 50 of 75\n",
      "Uploaded batch 51 of 75\n",
      "Uploaded batch 52 of 75\n",
      "Uploaded batch 53 of 75\n",
      "Uploaded batch 54 of 75\n",
      "Uploaded batch 55 of 75\n",
      "Uploaded batch 56 of 75\n",
      "Uploaded batch 57 of 75\n",
      "Uploaded batch 58 of 75\n",
      "Uploaded batch 59 of 75\n",
      "Uploaded batch 60 of 75\n",
      "Uploaded batch 61 of 75\n",
      "Uploaded batch 62 of 75\n",
      "Uploaded batch 63 of 75\n",
      "Uploaded batch 64 of 75\n",
      "Uploaded batch 65 of 75\n",
      "Uploaded batch 66 of 75\n",
      "Uploaded batch 67 of 75\n",
      "Uploaded batch 68 of 75\n",
      "Uploaded batch 69 of 75\n",
      "Uploaded batch 70 of 75\n",
      "Uploaded batch 71 of 75\n",
      "Uploaded batch 72 of 75\n",
      "Uploaded batch 73 of 75\n",
      "Uploaded batch 74 of 75\n",
      "Data upload complete!\n"
     ]
    }
   ],
   "source": [
    "upload_In_Batches(merged_data_to_upsert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA RETRIEVAL AND RESPONSE GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_tags(text):\n",
    "    pattern = re.compile(r'<think>.*?</think>', re.DOTALL)\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "def only_p_tags(text):\n",
    "    descriptions = re.findall(r\"<p>(.*?)</p>\", text)\n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load embedding model\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/msmarco-bert-base-dot-v5\")  # Small and efficient\n",
    "# model_name = \"deepseek-r1-distill-llama-70b\"\n",
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "# model_name = \"mixtral-8x7b-32768\"\n",
    "\n",
    "# Call Groq API for response\n",
    "chat = ChatGroq(\n",
    "api_key = GROQ_API_KEY,\n",
    "model_name = model_name\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_unique_content_only(results):\n",
    "    \n",
    "    context = ''\n",
    "    for search_result in results: \n",
    "        for match in search_result[\"matches\"]:\n",
    "            if match['metadata']['text'] not in context:\n",
    "                context += f\"- {match['metadata']['text']}\\n\"\n",
    "    return context\n",
    "\n",
    "def retrieve_context(description):\n",
    "    results = []\n",
    "\n",
    "    for i in range(len(description)):\n",
    "        query_vector = embedding_model.encode(description[i]).tolist()\n",
    "        search_results = index.query(vector=query_vector, top_k=5, include_metadata=True)\n",
    "        results.append(search_results)\n",
    "    return results\n",
    "\n",
    "    \n",
    "def generate_final_output(report,type,disease,generated_text,context):\n",
    "    \n",
    "    \n",
    "    # Construct prompt\n",
    "    prompt = f\"\"\"You are a expert medical lab technician. You have to interpret the medical lab report of the patient. I have provided \n",
    "    you the lab report, the test type, the disease which the patient thinks he is suffereing from and some context which may assist you in interpreting the report.\n",
    "    Interpret the report in layman understandable form in just 2 lines, not more than that and donot write anything else other than the interpretation. If you think that\n",
    "    the disease he thinks he is suffering from do not match the report, you can mention that as well and recommend the possible diseases.In case the Context is not benificial,\n",
    "    you can ignore it and answer from your own knowledge. Also score your answer out of 10, but just the number in the markdown form, nothing else. The answer should not be more than 2 to 3 lines.\n",
    "    :\n",
    "        \n",
    "    Context: {context}\n",
    "    Type: {type}\n",
    "    Disease: {disease}\n",
    "    Report: {report}\n",
    "    Random Context (it can be wrong): {generated_text}\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    # # Call Groq API for response\n",
    "    # chat = ChatGroq(\n",
    "    # api_key = GROQ_API_KEY,\n",
    "    # model_name = model_name\n",
    "    # )   \n",
    "    \n",
    "    chain = chat | StrOutputParser()\n",
    "    \n",
    "    response = chain.invoke(prompt)\n",
    "    response = remove_tags(response)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_refined_prompt(query,type,disease):\n",
    "    \n",
    "    # Construct prompt\n",
    "    prompt = f\"\"\"You are an expert medical lab technician. I have provided the test type, the suspected disease (if mentioned by the patient), and the lab report. Since the lab report primarily consists of numerical values, retrieving relevant context from my RAG system is challenging. Your task is to generate a maximum of 200-300 words textual summary that best represents this report, incorporating key abnormalities or notable findings. Provide 2 descriptions which are inside the <p>*</p> tag (don't use any other mode for separating them). This summary will be used to fetch the most relevant medical context from my RAG, which, along with the report, will help the LLM provide an accurate interpretation.\n",
    "    For more context, the data i have scrapped is from Testing.com, medlinplus.com and some books.\n",
    "    Don't write anything else, other than the relavant interpretation.\n",
    "    :\n",
    "    \n",
    "    Type: {type}\n",
    "    Diesease: {disease}\n",
    "    Report: {query}\n",
    "        \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    chain = chat | StrOutputParser()\n",
    "    \n",
    "    response = chain.invoke(prompt)\n",
    "    response = remove_tags(response)\n",
    "    response = only_p_tags(response)\n",
    "    return response # returns the list of 3 description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def discard_irrelevant_context(test_name,normal_ranges,retrieved_context,report):\n",
    "    \n",
    "    # Construct prompt\n",
    "    prompt = f\"\"\"You are an expert medical lab technician. Your task is to extract only the most relevant information from the provided medical context and discard anything unrelated.  \n",
    "\n",
    "### Given Information:\n",
    "- **Test Type:** {test_name}  \n",
    "- **Medical Report:** {report}  \n",
    "- **Normal Ranges:** {normal_ranges}  \n",
    "- **Retrieved Context:** {retrieved_context}  \n",
    "\n",
    "### Instructions:\n",
    "- Read the retrieved context carefully.  \n",
    "- Identify the information that is directly relevant to the test {test_name} and the provided ranges (only\n",
    " consider the provided ranges if the normal ranges are not present in the test report, otherwise consider the provided ones).  \n",
    "- Extract only the relevant paragraphs and discard anything that is not directly related.  \n",
    "- Ensure that the extracted content provides useful insights about the given test.  \n",
    "\n",
    "### Output Format:\n",
    "Return the **filtered context** as clean paragraphs that are relevant to {test_name}. Do not include any unrelated information, just provide the paragraphs nothing else.  \n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    chain = chat | StrOutputParser()\n",
    "    \n",
    "    response = chain.invoke(prompt)\n",
    "    response = remove_tags(response)\n",
    "    return response # final paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The patient's lab report suggests they are suffering from Dengue Hemorrhagic Fever, not just dengue, due to the presence of hemorrhage, thrombocytopenia, and elevated liver enzymes. The report's findings are consistent with the typical clinical presentation of DHF, characterized by severe bleeding, low platelet count, and plasma leakage.\n",
      "#8\n"
     ]
    }
   ],
   "source": [
    "test_name = \" Dengue Hemorrhagic Fever \"\n",
    "disease = \"dengue\"\n",
    "\n",
    "report = '''Characteristic\tDF¹ (%)\tDHF¹ (%)\tN\tp-value²\n",
    "Demographics\t\t\t\t\n",
    "Age (median ± interquartile range)\t26.0 ± 19.0\t24.5 ± 18.0\t201\t0.905\n",
    "Gender\t\t\t\t\n",
    "Male\t99 (61.5)\t30 (75.0)\t201\t0.077\n",
    "Female\t62 (38.5)\t10 (25.0)\t\t\n",
    "Clinical Presentation\t\t\t\t\n",
    "Fever\t159/161 (98.8)\t39/39 (100.0)\t200\t0.647\n",
    "Nausea and/or vomiting\t93/161 (57.8)\t27/40 (67.5)\t201\t0.173\n",
    "Rash\t44/161 (27.3)\t31/40 (77.5)\t201\t<0.001\n",
    "Abdominal Pain\t6/86 (7.0)\t1/11 (9.1)\t97\t0.582\n",
    "Diarrhea\t26/161 (16.2)\t5/40 (12.5)\t201\t0.384\n",
    "Myalgia\t46/161 (28.6)\t6/40 (15.0)\t201\t0.056\n",
    "Headache\t21/161 (13.0)\t2/40 (5.0)\t201\t0.120\n",
    "Cough\t22/161 (13.7)\t1/40 (2.5)\t201\t0.033\n",
    "Hemorrhage\t6/161 (3.7)\t29/40 (72.5)\t201\t<0.001\n",
    "Temperature (median)\t38.00 ± 2.00\t37.00 ± 1.00\t177\t0.014\n",
    "Laboratory Findings\t\t\t\t\n",
    "Thrombocytopenia at presentation\t116/151 (76.8)\t36/40 (90.0)\t191\t0.047\n",
    "Received platelet transfusion\t25/90 (27.8)\t13/32 (40.6)\t122\t0.131\n",
    "Low Hemoglobin\t16/137 (11.7)\t8/37 (21.6)\t174\t0.102\n",
    "Hematocrit level on admission (median)\t39.50 ± 6.75\t40.40 ± 8.80\t167\t0.607\n",
    "Leukopenia\t64/141 (45.4)\t9/37 (24.3)\t178\t0.015\n",
    "Neutropenia\t35/133 (26.3)\t16/34 (47.1)\t167\t0.018\n",
    "Lymphocytosis\t30/132 (22.7)\t7/33 (21.2)\t165\t0.529\n",
    "Monocytosis\t32/122 (26.2)\t19/33 (57.6)\t155\t0.001\n",
    "Raised ALT\t63/110 (57.3)\t27/32 (84.4)\t142\t0.004\n",
    "Raised AST\t68/79 (86.1)\t25/26 (96.2)\t105\t0.147'''\n",
    "generated_text = generate_refined_prompt(report,test_name,disease) # list of 2 descriptions\n",
    "retrieved_content = retrieve_context(generated_text)\n",
    "unique_content = get_unique_content_only(retrieved_content)\n",
    "context = discard_irrelevant_context(test_name,None,unique_content,report)\n",
    "response = generate_final_output(report,test_name,disease,generated_text,context)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22.6 / 15.0 / 18.2\n",
    "# 10\n",
    "# 4.5\n",
    "# 4.4\n",
    "# 2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report = \"\"\"Complete Blood Count (CBC) Report\n",
    "# Test\tResult\tReference Range\tUnits\tFlag\n",
    "# White Blood Cell Count (WBC)\t7.5\t4.0 - 11.0\tx10³/μL\tNormal\n",
    "# Red Blood Cell Count (RBC)\t3\t4.5 - 5.9\tx10⁶/μL\tAbnormal\n",
    "# Hemoglobin (Hgb)\t15.0\t13.5 - 17.5\tg/dL\tNormal\n",
    "# Hematocrit (Hct)\t45\t40 - 52\t%\tNormal\n",
    "# Mean Corpuscular Volume (MCV)\t88\t80 - 100\tfL\tNormal\n",
    "# Mean Corpuscular Hemoglobin (MCH)\t29\t27 - 34\tpg\tNormal\n",
    "# Mean Corpuscular Hemoglobin Concentration (MCHC)\t34\t32 - 36\tg/dL\tNormal\n",
    "# Red Cell Distribution Width (RDW)\t13.5\t11.5 - 14.5\t%\tNormal\n",
    "# Platelet Count\t250\t150 - 450\tx10³/μL\tNormal\n",
    "# Neutrophils\t35\t40 - 70\t%\tAbnormal\n",
    "# Lymphocytes\t10\t20 - 40\t%\tAbnormal\n",
    "# Monocytes\t6\t2 - 10\t%\tNormal\n",
    "# Eosinophils\t3\t1 - 4\t%\tNormal\n",
    "# Basophils\t1\t0 - 2\t%\tNormal\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
