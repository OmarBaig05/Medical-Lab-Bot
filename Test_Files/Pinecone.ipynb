{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\D\\Work\\Projects\\Medical Lab Bot\\Test_Files\\.venv\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from pinecone import Pinecone\n",
    "import fitz\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "CHUNK_SIZE = 128\n",
    "\n",
    "dotenv.load_dotenv(\".env\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.data.index.Index at 0x2005a761b50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"medicalbot-vdb\"\n",
    "index = pc.Index(index_name)\n",
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FILES TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing complete. CSV file saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    return \"\\n\".join([page.get_text(\"text\") for page in doc])\n",
    "\n",
    "# Function to split text into chunks\n",
    "def create_text_chunks(text, chunk_size=CHUNK_SIZE):\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "# Function to extract headings and map content to them\n",
    "def extract_headings_and_text(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    extracted_data = []\n",
    "    current_heading = None\n",
    "    buffer = []\n",
    "    \n",
    "    for line in lines:\n",
    "        if line.isupper() and len(line) > 3:  # Heuristic for headings\n",
    "            if buffer:\n",
    "                extracted_data.append((current_heading, \" \".join(buffer)))\n",
    "                buffer = []\n",
    "            current_heading = line.strip()\n",
    "        else:\n",
    "            buffer.append(line.strip())\n",
    "    \n",
    "    if buffer:\n",
    "        extracted_data.append((current_heading, \" \".join(buffer)))\n",
    "    \n",
    "    return extracted_data\n",
    "\n",
    "# Function to create a structured DataFrame\n",
    "def create_dataframe_from_text_files(txt_folder):\n",
    "    data_list = []\n",
    "    txt_files = sorted(os.listdir(txt_folder), key=lambda x: int(x.split(\".\")[0]))\n",
    "    \n",
    "    for txt_file in txt_files:\n",
    "        txt_path = os.path.join(txt_folder, txt_file)\n",
    "        with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text_data = f.read()\n",
    "        \n",
    "        extracted_data = extract_headings_and_text(text_data)\n",
    "        text_chunks = create_text_chunks(text_data)\n",
    "        \n",
    "        for chunk in text_chunks:\n",
    "            test_name, source = \"No_testName\", \"No_Source\"\n",
    "            \n",
    "            for heading, content in extracted_data:\n",
    "                if chunk in content:\n",
    "                    test_name = heading\n",
    "                    source = heading\n",
    "                    break\n",
    "            \n",
    "            data_list.append({\n",
    "                \"Test Name\": test_name,\n",
    "                \"Description\": chunk,\n",
    "                \"Source\": source,\n",
    "                \"URL\": \"No_URl\"\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(data_list)\n",
    "\n",
    "# Function to save DataFrame to a CSV file\n",
    "def save_dataframe(df, output_path):\n",
    "    df.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# Main execution\n",
    "txt_folder = \"../DATA/TextFiles\"\n",
    "df = create_dataframe_from_text_files(txt_folder)\n",
    "save_dataframe(df, \"structured_data.csv\")\n",
    "\n",
    "print(\"Data processing complete. CSV file saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def upsert_data_to_pinecone(df):\n",
    "    # Ensure the \"tokens\" column is in the correct format (list of floats)\n",
    "    df[\"tokens\"] = df[\"tokens\"].apply(eval)  # Convert string representation of list to actual list\n",
    "    print(\"1: \",len(df))\n",
    "    # Prepare data for upserting into Pinecone\n",
    "    df = df.fillna(\"\")  # Replace NaN with an empty string\n",
    "    print(\"1: \",len(df))\n",
    "    print(\"Uploading data to Pinecone...\")\n",
    "    data_to_upsert = []\n",
    "    for idx, row in df.iterrows():\n",
    "        metadata = {\n",
    "            \"test_name\": row[\"Test Name\"],\n",
    "            \"source\": row[\"Source\"],\n",
    "            \"url\": row[\"URL\"],\n",
    "            \"text\": row[\"text\"]\n",
    "        }\n",
    "        data_to_upsert.append({\"id\": str(idx), \"values\": row[\"tokens\"], \"metadata\": metadata})\n",
    "\n",
    "    return data_to_upsert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_In_Batches(data_to_upsert, batch_size=100):\n",
    "    # Batch upload\n",
    "    for i in range(0, len(data_to_upsert), batch_size):\n",
    "        batch = data_to_upsert[i:i + batch_size]\n",
    "        index.upsert(vectors=batch)\n",
    "        print(f\"Uploaded batch {i // batch_size + 1} of {len(data_to_upsert) // batch_size + 1}\")\n",
    "        \n",
    "    print(\"Data upload complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your DataFrame\n",
    "df = pd.read_csv(\"../DATA/Embedded_Files/medlinePlus_tokens.csv\")  # Replace with your file path\n",
    "df2 = pd.read_csv(\"../DATA/Embedded_Files/testing_com_tokens.csv\")  # Replace with your file path\n",
    "df3 = pd.read_csv(\"../DATA/Embedded_Files/files_tokens.csv\")  # Replace with your file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:  2803\n",
      "1:  2803\n",
      "Uploading data to Pinecone...\n",
      "1:  3449\n",
      "1:  3449\n",
      "Uploading data to Pinecone...\n",
      "1:  2906\n",
      "1:  2906\n",
      "Uploading data to Pinecone...\n"
     ]
    }
   ],
   "source": [
    "data_to_upsert = upsert_data_to_pinecone(df)\n",
    "data_to_upsert2 = upsert_data_to_pinecone(df2)\n",
    "data_to_upsert3 = upsert_data_to_pinecone(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2803\n",
      "3449\n",
      "2906\n"
     ]
    }
   ],
   "source": [
    "print(len(data_to_upsert))\n",
    "print(len(data_to_upsert2))\n",
    "print(len(data_to_upsert3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9158"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data_to_upsert = data_to_upsert + data_to_upsert2 + data_to_upsert3\n",
    "len(merged_data_to_upsert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded batch 1 of 92\n",
      "Uploaded batch 2 of 92\n",
      "Uploaded batch 3 of 92\n",
      "Uploaded batch 4 of 92\n",
      "Uploaded batch 5 of 92\n",
      "Uploaded batch 6 of 92\n",
      "Uploaded batch 7 of 92\n",
      "Uploaded batch 8 of 92\n",
      "Uploaded batch 9 of 92\n",
      "Uploaded batch 10 of 92\n",
      "Uploaded batch 11 of 92\n",
      "Uploaded batch 12 of 92\n",
      "Uploaded batch 13 of 92\n",
      "Uploaded batch 14 of 92\n",
      "Uploaded batch 15 of 92\n",
      "Uploaded batch 16 of 92\n",
      "Uploaded batch 17 of 92\n",
      "Uploaded batch 18 of 92\n",
      "Uploaded batch 19 of 92\n",
      "Uploaded batch 20 of 92\n",
      "Uploaded batch 21 of 92\n",
      "Uploaded batch 22 of 92\n",
      "Uploaded batch 23 of 92\n",
      "Uploaded batch 24 of 92\n",
      "Uploaded batch 25 of 92\n",
      "Uploaded batch 26 of 92\n",
      "Uploaded batch 27 of 92\n",
      "Uploaded batch 28 of 92\n",
      "Uploaded batch 29 of 92\n",
      "Uploaded batch 30 of 92\n",
      "Uploaded batch 31 of 92\n",
      "Uploaded batch 32 of 92\n",
      "Uploaded batch 33 of 92\n",
      "Uploaded batch 34 of 92\n",
      "Uploaded batch 35 of 92\n",
      "Uploaded batch 36 of 92\n",
      "Uploaded batch 37 of 92\n",
      "Uploaded batch 38 of 92\n",
      "Uploaded batch 39 of 92\n",
      "Uploaded batch 40 of 92\n",
      "Uploaded batch 41 of 92\n",
      "Uploaded batch 42 of 92\n",
      "Uploaded batch 43 of 92\n",
      "Uploaded batch 44 of 92\n",
      "Uploaded batch 45 of 92\n",
      "Uploaded batch 46 of 92\n",
      "Uploaded batch 47 of 92\n",
      "Uploaded batch 48 of 92\n",
      "Uploaded batch 49 of 92\n",
      "Uploaded batch 50 of 92\n",
      "Uploaded batch 51 of 92\n",
      "Uploaded batch 52 of 92\n",
      "Uploaded batch 53 of 92\n",
      "Uploaded batch 54 of 92\n",
      "Uploaded batch 55 of 92\n",
      "Uploaded batch 56 of 92\n",
      "Uploaded batch 57 of 92\n",
      "Uploaded batch 58 of 92\n",
      "Uploaded batch 59 of 92\n",
      "Uploaded batch 60 of 92\n",
      "Uploaded batch 61 of 92\n",
      "Uploaded batch 62 of 92\n",
      "Uploaded batch 63 of 92\n",
      "Uploaded batch 64 of 92\n",
      "Uploaded batch 65 of 92\n",
      "Uploaded batch 66 of 92\n",
      "Uploaded batch 67 of 92\n",
      "Uploaded batch 68 of 92\n",
      "Uploaded batch 69 of 92\n",
      "Uploaded batch 70 of 92\n",
      "Uploaded batch 71 of 92\n",
      "Uploaded batch 72 of 92\n",
      "Uploaded batch 73 of 92\n",
      "Uploaded batch 74 of 92\n",
      "Uploaded batch 75 of 92\n",
      "Uploaded batch 76 of 92\n",
      "Uploaded batch 77 of 92\n",
      "Uploaded batch 78 of 92\n",
      "Uploaded batch 79 of 92\n",
      "Uploaded batch 80 of 92\n",
      "Uploaded batch 81 of 92\n",
      "Uploaded batch 82 of 92\n",
      "Uploaded batch 83 of 92\n",
      "Uploaded batch 84 of 92\n",
      "Uploaded batch 85 of 92\n",
      "Uploaded batch 86 of 92\n",
      "Uploaded batch 87 of 92\n",
      "Uploaded batch 88 of 92\n",
      "Uploaded batch 89 of 92\n",
      "Uploaded batch 90 of 92\n",
      "Uploaded batch 91 of 92\n",
      "Uploaded batch 92 of 92\n",
      "Data upload complete!\n"
     ]
    }
   ],
   "source": [
    "upload_In_Batches(merged_data_to_upsert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA RETRIEVAL AND RESPONSE GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_tags(text):\n",
    "    pattern = re.compile(r'<think>.*?</think>', re.DOTALL)\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "def only_p_tags(text):\n",
    "    descriptions = re.findall(r\"<p>(.*?)</p>\", text)\n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load embedding model\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Small and efficient\n",
    "# model_name = \"deepseek-r1-distill-llama-70b\"\n",
    "# model_name = \"llama-3.3-70b-versatile\"\n",
    "model_name = \"mixtral-8x7b-32768\"\n",
    "\n",
    "# Call Groq API for response\n",
    "chat = ChatGroq(\n",
    "api_key = GROQ_API_KEY,\n",
    "model_name = model_name\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_unique_content_only(results):\n",
    "    \n",
    "    context = ''\n",
    "    for search_result in results: \n",
    "        for match in search_result[\"matches\"]:\n",
    "            if match['metadata']['text'] not in context:\n",
    "                context += f\"- {match['metadata']['text']}\\n\"\n",
    "    return context\n",
    "\n",
    "def retrieve_context(description):\n",
    "    results = []\n",
    "\n",
    "    for i in range(len(description)):\n",
    "        query_vector = embedding_model.encode(description[i]).tolist()\n",
    "        search_results = index.query(vector=query_vector, top_k=5, include_metadata=True)\n",
    "        results.append(search_results)\n",
    "    return results\n",
    "\n",
    "    \n",
    "def generate_final_output(report,type,disease,generated_text,context):\n",
    "    \n",
    "    \n",
    "    # Construct prompt\n",
    "    prompt = f\"\"\"You are a expert medical lab technician. You have to interpret the medical lab report of the patient. I have provided \n",
    "    you the lab report, the test type, the disease which the patient thinks he is suffereing from and some context which may assist you in interpreting the report.\n",
    "    Interpret the report in layman understandable form in just 2 lines, not more than that and donot write anything else other than the interpretation. If you think that\n",
    "    the disease he thinks he is suffering from do not match the report, you can mention that as well and recommend the possible diseases.In case the Context is not benificial,\n",
    "    you can ignore it and answer from your own knowledge. Also score your answer out of 10, but just the number in the markdown form, nothing else. The answer should not be more than 2 to 3 lines.\n",
    "    :\n",
    "        \n",
    "    Context: {context}\n",
    "    Type: {type}\n",
    "    Disease: {disease}\n",
    "    Report: {report}\n",
    "    Random Context (it can be wrong): {generated_text}\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    # # Call Groq API for response\n",
    "    # chat = ChatGroq(\n",
    "    # api_key = GROQ_API_KEY,\n",
    "    # model_name = model_name\n",
    "    # )   \n",
    "    \n",
    "    chain = chat | StrOutputParser()\n",
    "    \n",
    "    response = chain.invoke(prompt)\n",
    "    response = remove_tags(response)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_refined_prompt(query,type,disease):\n",
    "    \n",
    "    # Construct prompt\n",
    "    prompt = f\"\"\"You are an expert medical lab technician. I have provided the test type, the suspected disease (if mentioned by the patient), and the lab report. Since the lab report primarily consists of numerical values, retrieving relevant context from my RAG system is challenging. Your task is to generate a concise 2-3 line textual summary that best represents this report, incorporating key abnormalities or notable findings. Provide 3 descriptions which are inside the <p>*</p> tag (don't use any other mode for separating them). This summary will be used to fetch the most relevant medical context from my RAG, which, along with the report, will help the LLM provide an accurate interpretation.\n",
    "    For more context, the data i have scrapped is from Testing.com, medlinplus.com and some books.\n",
    "    Don't write anything else, other than the relavant interpretation.\n",
    "    :\n",
    "    \n",
    "    Type: {type}\n",
    "    Diesease: {disease}\n",
    "    Report: {query}\n",
    "        \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call Groq API for response\n",
    "    # chat = ChatGroq(\n",
    "    # api_key = GROQ_API_KEY,\n",
    "    # model_name = model_name\n",
    "    # )   \n",
    "    \n",
    "    chain = chat | StrOutputParser()\n",
    "    \n",
    "    response = chain.invoke(prompt)\n",
    "    response = remove_tags(response)\n",
    "    response = only_p_tags(response)\n",
    "    return response # returns the list of 3 description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def discard_irrelevant_context(test_name,normal_ranges,retrieved_context,report):\n",
    "    \n",
    "    # Construct prompt\n",
    "    prompt = f\"\"\"You are an expert medical lab technician. Your task is to extract only the most relevant information from the provided medical context and discard anything unrelated.  \n",
    "\n",
    "### Given Information:\n",
    "- **Test Type:** {test_name}  \n",
    "- **Medical Report:** {report}  \n",
    "- **Normal Ranges:** {normal_ranges}  \n",
    "- **Retrieved Context:** {retrieved_context}  \n",
    "\n",
    "### Instructions:\n",
    "- Read the retrieved context carefully.  \n",
    "- Identify the information that is directly relevant to the test {test_name} and the provided ranges (only\n",
    " consider the provided ranges if the normal ranges are not present in the test report, otherwise consider the provided ones).  \n",
    "- Extract only the relevant paragraphs and discard anything that is not directly related.  \n",
    "- Ensure that the extracted content provides useful insights about the given test.  \n",
    "\n",
    "### Output Format:\n",
    "Return the **filtered context** as clean paragraphs that are relevant to {test_name}. Do not include any unrelated information, just provide the paragraphs nothing else.  \n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    chain = chat | StrOutputParser()\n",
    "    \n",
    "    response = chain.invoke(prompt)\n",
    "    response = remove_tags(response)\n",
    "    return response # final paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Complete Blood Count (CBC) is a test that provides information about the number and type of cells in the blood. Here are the relevant details extracted from the provided context:\n",
      "\n",
      "- Red Blood Cell Count (RBC) reflects the number of circulating red blood cells. A decrease in the RBC count indicates anemia, while an elevated RBC count may suggest polycythemia vera or dehydration.\n",
      "\n",
      "- Hemoglobin (Hgb) is a protein within the cytoplasm of the red blood cells, which plays a role in tissue perfusion. It is the most commonly used marker of anemia.\n",
      "\n",
      "- Hematocrit (Hct) measures the percentage of red blood cells in the blood. Like hemoglobin, it can be used to diagnose anemia or polycythemia.\n",
      "\n",
      "- Mean Corpuscular Volume (MCV) measures the average size of the red blood cells. Low MCV indicates microcytic anemia, while high MCV suggests macrocytic anemia.\n",
      "\n",
      "- Mean Corpuscular Hemoglobin (MCH) measures the average amount of hemoglobin in the red blood cells. Low MCH is indicative of hypochromic anemia, while high MCH suggests hyperchromic anemia.\n",
      "\n",
      "- Mean Corpuscular Hemoglobin Concentration (MCHC) measures the average concentration of hemoglobin in the red blood cells. Low MCHC indicates hypochromic anemia, while high MCHC suggests hyperchromic anemia.\n",
      "\n",
      "- Red Cell Distribution Width (RDW) measures the variability in red blood cell size. High RDW is seen in anisocytosis or dimorphic RBC populations.\n",
      "\n",
      "- White Blood Cell Count (WBC) reflects the number of white blood cells in the blood. High WBC may indicate an infection or inflammation, while low WBC can suggest a weakened immune system.\n",
      "\n",
      "- Neutrophils, lymphocytes, monocytes, eosinophils, and basophils are different types of white blood cells with various functions. An increased or decreased count of these cells can provide clues about the patient's condition. For example, neutrophilia is commonly seen in patients with bacterial infection, while lymphocytosis may indicate a viral infection.\n",
      "\n",
      "- Platelets are small anuclear fragments of bone marrow megakaryocytes that maintain the integrity of the vascular tree and produce the platelet plug in the first phase of clotting. Low platelet count is known as thrombocytopenia, while high platelet count is known as thrombocytosis. Thrombocytopenia may suggest reduced platelet production or increased consumption or destruction of platelets. Thrombocytosis may be associated with chronic myeloproliferative diseases, carcinoma, chronic inflammatory diseases, hemorrhage, sickle cell disease, or iron deficiency anemia.\n",
      "------------------------------\n",
      "Red Blood Cell count is low, suggesting anemia but not consistent with dengue. Neutrophils and Lymphocytes are abnormal, indicating a potential infection. Score: 9/10\n"
     ]
    }
   ],
   "source": [
    "test_name = \"CBC\"\n",
    "disease = \"dengue\"\n",
    "report = \"\"\"Complete Blood Count (CBC) Report\n",
    "Test\tResult\tReference Range\tUnits\tFlag\n",
    "White Blood Cell Count (WBC)\t7.5\t4.0 - 11.0\tx10³/μL\tNormal\n",
    "Red Blood Cell Count (RBC)\t3\t4.5 - 5.9\tx10⁶/μL\tAbnormal\n",
    "Hemoglobin (Hgb)\t15.0\t13.5 - 17.5\tg/dL\tNormal\n",
    "Hematocrit (Hct)\t45\t40 - 52\t%\tNormal\n",
    "Mean Corpuscular Volume (MCV)\t88\t80 - 100\tfL\tNormal\n",
    "Mean Corpuscular Hemoglobin (MCH)\t29\t27 - 34\tpg\tNormal\n",
    "Mean Corpuscular Hemoglobin Concentration (MCHC)\t34\t32 - 36\tg/dL\tNormal\n",
    "Red Cell Distribution Width (RDW)\t13.5\t11.5 - 14.5\t%\tNormal\n",
    "Platelet Count\t250\t150 - 450\tx10³/μL\tNormal\n",
    "Neutrophils\t35\t40 - 70\t%\tAbnormal\n",
    "Lymphocytes\t10\t20 - 40\t%\tAbnormal\n",
    "Monocytes\t6\t2 - 10\t%\tNormal\n",
    "Eosinophils\t3\t1 - 4\t%\tNormal\n",
    "Basophils\t1\t0 - 2\t%\tNormal\"\"\"\n",
    "generated_text = generate_refined_prompt(report,test_name,disease) # list of 3 descriptions\n",
    "\n",
    "retrieved_content = retrieve_context(generated_text)\n",
    "unique_content = get_unique_content_only(retrieved_content)\n",
    "\n",
    "context = discard_irrelevant_context(test_name,None,unique_content,report)\n",
    "print(context)\n",
    "\n",
    "print(\"------------------------------\")\n",
    "response = generate_final_output(report,test_name,disease,generated_text,context)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
