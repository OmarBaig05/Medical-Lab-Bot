{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from pinecone import Pinecone\n",
    "import fitz\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "CHUNK_SIZE = 128\n",
    "\n",
    "dotenv.load_dotenv(\".env\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.data.index.Index at 0x2c2ff4d3ad0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"medicalbot-vdb\"\n",
    "index = pc.Index(index_name)\n",
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FILES TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing complete. CSV file saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    return \"\\n\".join([page.get_text(\"text\") for page in doc])\n",
    "\n",
    "# Function to split text into chunks\n",
    "def create_text_chunks(text, chunk_size=CHUNK_SIZE):\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "# Function to extract headings and map content to them\n",
    "def extract_headings_and_text(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    extracted_data = []\n",
    "    current_heading = None\n",
    "    buffer = []\n",
    "    \n",
    "    for line in lines:\n",
    "        if line.isupper() and len(line) > 3:  # Heuristic for headings\n",
    "            if buffer:\n",
    "                extracted_data.append((current_heading, \" \".join(buffer)))\n",
    "                buffer = []\n",
    "            current_heading = line.strip()\n",
    "        else:\n",
    "            buffer.append(line.strip())\n",
    "    \n",
    "    if buffer:\n",
    "        extracted_data.append((current_heading, \" \".join(buffer)))\n",
    "    \n",
    "    return extracted_data\n",
    "\n",
    "# Function to create a structured DataFrame\n",
    "def create_dataframe_from_text_files(txt_folder):\n",
    "    data_list = []\n",
    "    txt_files = sorted(os.listdir(txt_folder), key=lambda x: int(x.split(\".\")[0]))\n",
    "    \n",
    "    for txt_file in txt_files:\n",
    "        txt_path = os.path.join(txt_folder, txt_file)\n",
    "        with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text_data = f.read()\n",
    "        \n",
    "        extracted_data = extract_headings_and_text(text_data)\n",
    "        text_chunks = create_text_chunks(text_data)\n",
    "        \n",
    "        for chunk in text_chunks:\n",
    "            test_name, source = \"No_testName\", \"No_Source\"\n",
    "            \n",
    "            for heading, content in extracted_data:\n",
    "                if chunk in content:\n",
    "                    test_name = heading\n",
    "                    source = heading\n",
    "                    break\n",
    "            \n",
    "            data_list.append({\n",
    "                \"Test Name\": test_name,\n",
    "                \"Description\": chunk,\n",
    "                \"Source\": source,\n",
    "                \"URL\": \"No_URl\"\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(data_list)\n",
    "\n",
    "# Function to save DataFrame to a CSV file\n",
    "def save_dataframe(df, output_path):\n",
    "    df.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# Main execution\n",
    "txt_folder = \"../DATA/TextFiles\"\n",
    "df = create_dataframe_from_text_files(txt_folder)\n",
    "save_dataframe(df, \"structured_data.csv\")\n",
    "\n",
    "print(\"Data processing complete. CSV file saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def upsert_data_to_pinecone(df):\n",
    "    # Ensure the \"tokens\" column is in the correct format (list of floats)\n",
    "    df[\"tokens\"] = df[\"tokens\"].apply(eval)  # Convert string representation of list to actual list\n",
    "    print(\"1: \",len(df))\n",
    "    # Prepare data for upserting into Pinecone\n",
    "    df = df.fillna(\"\")  # Replace NaN with an empty string\n",
    "    print(\"1: \",len(df))\n",
    "    print(\"Uploading data to Pinecone...\")\n",
    "    data_to_upsert = []\n",
    "    for idx, row in df.iterrows():\n",
    "        metadata = {\n",
    "            \"test_name\": row[\"Test Name\"],\n",
    "            \"source\": row[\"Source\"],\n",
    "            \"url\": row[\"URL\"],\n",
    "            \"text\": row[\"text\"]\n",
    "        }\n",
    "        data_to_upsert.append({\"id\": str(idx), \"values\": row[\"tokens\"], \"metadata\": metadata})\n",
    "\n",
    "    return data_to_upsert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_In_Batches(data_to_upsert, batch_size=100):\n",
    "    # Batch upload\n",
    "    for i in range(0, len(data_to_upsert), batch_size):\n",
    "        batch = data_to_upsert[i:i + batch_size]\n",
    "        index.upsert(vectors=batch)\n",
    "        print(f\"Uploaded batch {i // batch_size + 1} of {len(data_to_upsert) // batch_size + 1}\")\n",
    "        \n",
    "    print(\"Data upload complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your DataFrame\n",
    "df = pd.read_csv(\"../DATA/Embedded_Files/medlinePlus_tokens.csv\")  # Replace with your file path\n",
    "df2 = pd.read_csv(\"../DATA/Embedded_Files/testing_com_tokens.csv\")  # Replace with your file path\n",
    "df3 = pd.read_csv(\"../DATA/Embedded_Files/files_tokens.csv\")  # Replace with your file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:  2803\n",
      "1:  2803\n",
      "Uploading data to Pinecone...\n",
      "1:  3449\n",
      "1:  3449\n",
      "Uploading data to Pinecone...\n",
      "1:  2906\n",
      "1:  2906\n",
      "Uploading data to Pinecone...\n"
     ]
    }
   ],
   "source": [
    "data_to_upsert = upsert_data_to_pinecone(df)\n",
    "data_to_upsert2 = upsert_data_to_pinecone(df2)\n",
    "data_to_upsert3 = upsert_data_to_pinecone(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2803\n",
      "3449\n",
      "2906\n"
     ]
    }
   ],
   "source": [
    "print(len(data_to_upsert))\n",
    "print(len(data_to_upsert2))\n",
    "print(len(data_to_upsert3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9158"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data_to_upsert = data_to_upsert + data_to_upsert2 + data_to_upsert3\n",
    "len(merged_data_to_upsert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded batch 1 of 92\n",
      "Uploaded batch 2 of 92\n",
      "Uploaded batch 3 of 92\n",
      "Uploaded batch 4 of 92\n",
      "Uploaded batch 5 of 92\n",
      "Uploaded batch 6 of 92\n",
      "Uploaded batch 7 of 92\n",
      "Uploaded batch 8 of 92\n",
      "Uploaded batch 9 of 92\n",
      "Uploaded batch 10 of 92\n",
      "Uploaded batch 11 of 92\n",
      "Uploaded batch 12 of 92\n",
      "Uploaded batch 13 of 92\n",
      "Uploaded batch 14 of 92\n",
      "Uploaded batch 15 of 92\n",
      "Uploaded batch 16 of 92\n",
      "Uploaded batch 17 of 92\n",
      "Uploaded batch 18 of 92\n",
      "Uploaded batch 19 of 92\n",
      "Uploaded batch 20 of 92\n",
      "Uploaded batch 21 of 92\n",
      "Uploaded batch 22 of 92\n",
      "Uploaded batch 23 of 92\n",
      "Uploaded batch 24 of 92\n",
      "Uploaded batch 25 of 92\n",
      "Uploaded batch 26 of 92\n",
      "Uploaded batch 27 of 92\n",
      "Uploaded batch 28 of 92\n",
      "Uploaded batch 29 of 92\n",
      "Uploaded batch 30 of 92\n",
      "Uploaded batch 31 of 92\n",
      "Uploaded batch 32 of 92\n",
      "Uploaded batch 33 of 92\n",
      "Uploaded batch 34 of 92\n",
      "Uploaded batch 35 of 92\n",
      "Uploaded batch 36 of 92\n",
      "Uploaded batch 37 of 92\n",
      "Uploaded batch 38 of 92\n",
      "Uploaded batch 39 of 92\n",
      "Uploaded batch 40 of 92\n",
      "Uploaded batch 41 of 92\n",
      "Uploaded batch 42 of 92\n",
      "Uploaded batch 43 of 92\n",
      "Uploaded batch 44 of 92\n",
      "Uploaded batch 45 of 92\n",
      "Uploaded batch 46 of 92\n",
      "Uploaded batch 47 of 92\n",
      "Uploaded batch 48 of 92\n",
      "Uploaded batch 49 of 92\n",
      "Uploaded batch 50 of 92\n",
      "Uploaded batch 51 of 92\n",
      "Uploaded batch 52 of 92\n",
      "Uploaded batch 53 of 92\n",
      "Uploaded batch 54 of 92\n",
      "Uploaded batch 55 of 92\n",
      "Uploaded batch 56 of 92\n",
      "Uploaded batch 57 of 92\n",
      "Uploaded batch 58 of 92\n",
      "Uploaded batch 59 of 92\n",
      "Uploaded batch 60 of 92\n",
      "Uploaded batch 61 of 92\n",
      "Uploaded batch 62 of 92\n",
      "Uploaded batch 63 of 92\n",
      "Uploaded batch 64 of 92\n",
      "Uploaded batch 65 of 92\n",
      "Uploaded batch 66 of 92\n",
      "Uploaded batch 67 of 92\n",
      "Uploaded batch 68 of 92\n",
      "Uploaded batch 69 of 92\n",
      "Uploaded batch 70 of 92\n",
      "Uploaded batch 71 of 92\n",
      "Uploaded batch 72 of 92\n",
      "Uploaded batch 73 of 92\n",
      "Uploaded batch 74 of 92\n",
      "Uploaded batch 75 of 92\n",
      "Uploaded batch 76 of 92\n",
      "Uploaded batch 77 of 92\n",
      "Uploaded batch 78 of 92\n",
      "Uploaded batch 79 of 92\n",
      "Uploaded batch 80 of 92\n",
      "Uploaded batch 81 of 92\n",
      "Uploaded batch 82 of 92\n",
      "Uploaded batch 83 of 92\n",
      "Uploaded batch 84 of 92\n",
      "Uploaded batch 85 of 92\n",
      "Uploaded batch 86 of 92\n",
      "Uploaded batch 87 of 92\n",
      "Uploaded batch 88 of 92\n",
      "Uploaded batch 89 of 92\n",
      "Uploaded batch 90 of 92\n",
      "Uploaded batch 91 of 92\n",
      "Uploaded batch 92 of 92\n",
      "Data upload complete!\n"
     ]
    }
   ],
   "source": [
    "upload_In_Batches(merged_data_to_upsert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA RETRIEVAL AND RESPONSE GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embedding model\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Small and efficient\n",
    "\n",
    "def retrieve_and_generate(report,type,disease,generated_text):\n",
    "    query_vector = embedding_model.encode(generated_text).tolist()\n",
    "\n",
    "    # Search in Pinecone\n",
    "    search_results = index.query(vector=query_vector, top_k=5,include_values=True, include_metadata=True)\n",
    "\n",
    "    # Extract relevant context\n",
    "    context = \"\\n\".join([f\"- {match['metadata']['test_name']}: {match['metadata']['text']}\" \n",
    "                          for match in search_results[\"matches\"]])\n",
    "    \n",
    "    # Construct prompt\n",
    "    prompt = f\"\"\"You are a expert medical lab technician. You have to interpret the medical lab report of the patient. I have provided \n",
    "    you the lab report, the test type, the disease which the patient thinks he is suffereing from and some context which may assist you in interpreting the report.\n",
    "    Interpret the report in layman understandable form in just 2 lines, not more than that and donot write anything else other than the interpretation.\n",
    "    In case the Context is not benificial, you can ignore it and answer from your own knowledge.\n",
    "    :\n",
    "        \n",
    "    Context: {context}\n",
    "    Type: {type}\n",
    "    Disease: {disease}\n",
    "    Report: {report}\n",
    "    Random Context (it can be wrong): {generated_text}\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call Groq API for response\n",
    "    chat = ChatGroq(\n",
    "    api_key = GROQ_API_KEY,\n",
    "    model_name = \"llama-3.3-70b-versatile\"\n",
    "    )   \n",
    "    \n",
    "    chain = chat | StrOutputParser()\n",
    "    \n",
    "    response = chain.invoke(prompt)\n",
    "    return response,context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def retrieve_and_generate_prompt(query,type,disease):\n",
    "    \n",
    "    # Construct prompt\n",
    "    prompt = f\"\"\"You are an expert medical lab technician. I have provided the test type, the suspected disease (if mentioned by the patient), and the lab report. Since the lab report primarily consists of numerical values, retrieving relevant context from my RAG system is challenging. Your task is to generate a concise 2-3 line textual summary that best represents this report, incorporating key abnormalities or notable findings. This summary will be used to fetch the most relevant medical context from my RAG, which, along with the report, will help the LLM provide an accurate interpretation.\n",
    "    For more context, the data i have scrapped is from Testing.com, medlinplus.com and some books.\n",
    "    Don't write anything else, other than the relavant interpretation.\n",
    "    :\n",
    "    \n",
    "    Type: {type}\n",
    "    Diesease: {disease}\n",
    "    Report: {query}\n",
    "        \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call Groq API for response\n",
    "    chat = ChatGroq(\n",
    "    api_key = GROQ_API_KEY,\n",
    "    model_name = \"llama-3.3-70b-versatile\"\n",
    "    )   \n",
    "    \n",
    "    chain = chat | StrOutputParser()\n",
    "    \n",
    "    response = chain.invoke(prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low Red Blood Cell Count and abnormal neutrophil and lymphocyte percentages are noted in this CBC report, which may be relevant in the context of suspected dengue disease. The patient's RBC count is below the reference range, indicating anemia or possible blood loss. Neutrophil and lymphocyte percentages are also outside the normal range, suggesting an abnormal immune response.\n",
      "- Platelet Count: Test Quest Complete Blood Count Price 29 Type In person Sample Blood Tests for Red blood cells hemoglobin hematocrit mean corpuscular volume mean corpuscular hemoglobin mean corpuscular hemoglobin concentration red cell distribution width platelets mean platelet volume white blood cells neutrophils lymphocytes monocytes eosinophils basophils Results timeline A few business days Quest s Complete Blood Count includes the number of platelets per microliter in your blood sample as well as a mean platelet volume measuring their average size this is related to your physical performance blood clotting and risk of inflammation The test measures much more as well Your full report includes the following metrics Red blood cell RBC count A low RBC count may indicate anemia Conversely a high RBC count could be a sign of kidney\n",
      "- Complete Blood Count Cbc: may also look at the relationships between your different blood levels and will consider your current symptoms and health history The following sections describe some potential causes of high or low levels of RBCs WBCs or PLT but it is important to remember that an abnormal test result is not always a sign of a medical problem Some healthy people may have blood counts that fall outside the standard reference range Red blood cell measurements RBCs carry oxygen through the body and the RBC count shows the total number of RBCs found in your blood Hematocrit and hemoglobin are other related measures Anemia is a condition marked by low levels of RBCs There are many potential causes of abnormally low levels of RBCs hematocrit and or hemoglobin including\n",
      "- Platelet Count: or liver disease urinary tract infection or other urinary disorders The blood count also includes a tests measuring the average size of your RBCs and their size range throughout your body White blood cell WBC count Since WBCs stave off bacteria their presence in the urine can indicate a kidney or urinary tract infection WBC presence is also an early sign of leukemia in some cases Hematocrit Hematocrit refers to the percentage RBCs make up in your total blood supply Abnormally low or high red to white blood cell ratios may indicate adverse health conditions Hemoglobin Hemoglobin is a protein that gives blood its red color and ferries oxygen from the lungs to tissue throughout your body removing excess carbon dioxide in the process The blood count includes\n",
      "- Complete Blood Count Cbc: RBC counts are influenced by many different systems of the body and sometimes abnormal levels are related to more than one factor Your health care provider is in the best position to explain what the RBC measurements on your CBC mean for your health White blood cell counts WBCs are the main players of the immune system and the WBC count is the sum total of five different kinds of WBCs each plays a role in immune function A low level of WBCs is known as leukopenia Some of the possible causes of leukopenia include Liver damage including from alcohol abuse Severe infections An enlarged or damaged spleen Autoimmune diseases Conditions that disrupt bone marrow function Certain medications including many chemotherapies for cancer Having too many WBCs is\n",
      "- Red Blood Cell Count Rbc: determine its underlying cause RBC count may also be used to help diagnose other conditions that affect red blood cells such as kidney problems a type of white blood cell cancer or problems with the bone marrow What does the test measure RBC count is the number of RBCs contained in a sample of blood usually expressed as millions of cells per microliter number of RBCs x106 µL In a complete blood count CBC RBCs are measured along with white blood cells WBCs and platelets These cells are made in the bone marrow and released into the bloodstream as they mature In the blood these cells are suspended in a fluid called plasma In a healthy human weighing between 150 to 180 pounds the total blood volume is\n",
      "The patient's lab report shows a low Red Blood Cell Count, indicating possible anemia or blood loss, and abnormal neutrophil and lymphocyte percentages, which may be related to an immune response issue, consistent with suspected dengue disease. The patient's platelet count is normal, but the overall report suggests an underlying condition that needs further evaluation.\n"
     ]
    }
   ],
   "source": [
    "type = \"CBC\"\n",
    "disease = \"dengue\"\n",
    "query = \"\"\"Complete Blood Count (CBC) Report\n",
    "Test\tResult\tReference Range\tUnits\tFlag\n",
    "White Blood Cell Count (WBC)\t7.5\t4.0 - 11.0\tx10³/μL\tNormal\n",
    "Red Blood Cell Count (RBC)\t3\t4.5 - 5.9\tx10⁶/μL\tAbnormal\n",
    "Hemoglobin (Hgb)\t15.0\t13.5 - 17.5\tg/dL\tNormal\n",
    "Hematocrit (Hct)\t45\t40 - 52\t%\tNormal\n",
    "Mean Corpuscular Volume (MCV)\t88\t80 - 100\tfL\tNormal\n",
    "Mean Corpuscular Hemoglobin (MCH)\t29\t27 - 34\tpg\tNormal\n",
    "Mean Corpuscular Hemoglobin Concentration (MCHC)\t34\t32 - 36\tg/dL\tNormal\n",
    "Red Cell Distribution Width (RDW)\t13.5\t11.5 - 14.5\t%\tNormal\n",
    "Platelet Count\t250\t150 - 450\tx10³/μL\tNormal\n",
    "Neutrophils\t35\t40 - 70\t%\tAbnormal\n",
    "Lymphocytes\t10\t20 - 40\t%\tAbnormal\n",
    "Monocytes\t6\t2 - 10\t%\tNormal\n",
    "Eosinophils\t3\t1 - 4\t%\tNormal\n",
    "Basophils\t1\t0 - 2\t%\tNormal\"\"\"\n",
    "generated_text = retrieve_and_generate_prompt(query,type,disease)\n",
    "print(generated_text)\n",
    "response, context = retrieve_and_generate(query,type,disease,generated_text)\n",
    "print(context)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
