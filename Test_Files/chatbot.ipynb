{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\D\\Work\\Projects\\Medical Lab Bot\\Test_Files\\.venv\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import concurrent.futures\n",
    "import tiktoken\n",
    "from bs4 import BeautifulSoup\n",
    "from pinecone import Pinecone\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "dotenv.load_dotenv(\".env\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")    \n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "SERPER_API_KEY = os.getenv(\"SERPER_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://google.serper.dev/search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.data.index.Index at 0x20b83b77910>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index_name = \"medical-data\"\n",
    "# index_name = \"medicalbot-vdb\"\n",
    "index = pc.Index(index_name)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer(\"sentence-transformers/msmarco-bert-base-dot-v5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(text):\n",
    "    pattern = re.compile(r'<think>.*?</think>', re.DOTALL)\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "def only_p_tags(text):\n",
    "    descriptions = re.findall(r\"<p>(.*?)</p>\", text)\n",
    "    return descriptions\n",
    "\n",
    "\n",
    "def get_unique_content_only(results):\n",
    "    \n",
    "    context = ''\n",
    "    for search_result in results: \n",
    "        for match in search_result[\"matches\"]:\n",
    "            if match['metadata']['text'] not in context:\n",
    "                context += f\"- {match['metadata']['text']}\\n\"\n",
    "    return context\n",
    "\n",
    "def retrieve_context(description,embedding_model,index,top_k):\n",
    "    results = []\n",
    "\n",
    "    for i in range(len(description)):\n",
    "        query_vector = embedding_model.encode(description[i]).tolist()\n",
    "        search_results = index.query(vector=query_vector, top_k = top_k, include_metadata=True)\n",
    "        results.append(search_results)\n",
    "    return results\n",
    "\n",
    "def chunk_text(text,tokenizer, max_tokens):\n",
    "    \"\"\"Splits text into token-based chunks without cutting sentences abruptly.\"\"\"\n",
    "    \n",
    "    words = text.split()\n",
    "\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    token_count = 0\n",
    "\n",
    "    for word in words:\n",
    "        word_tokens = len(tokenizer.encode(word))  # Get token count for each word\n",
    "\n",
    "        if token_count + word_tokens > max_tokens:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = []\n",
    "            token_count = 0\n",
    "\n",
    "        current_chunk.append(word)\n",
    "        token_count += word_tokens\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def scrape_and_extract(url):\n",
    "    \"\"\"Scrape the webpage content.\"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Raise an error for bad status codes\n",
    "        return response.text\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans extracted web content by:\n",
    "    - Removing HTML tags\n",
    "    - Replacing multiple spaces/newlines/tabs with a single space\n",
    "    - Stripping leading/trailing whitespace\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "\n",
    "    # Remove HTML tags using BeautifulSoup\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    text = soup.get_text()\n",
    "\n",
    "    # Remove extra spaces, newlines, and tabs\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "def get_URLs(test_name,SERPER_API_KEY):\n",
    "    \"\"\"Search the web, scrape results, and generate an LLM response.\"\"\"\n",
    "    search_query = f\"How to interpret {test_name} report\"\n",
    "\n",
    "    payload = json.dumps({\n",
    "        \"q\": search_query,\n",
    "        \"num\": 2\n",
    "    })\n",
    "    headers = {\n",
    "    'X-API-KEY': SERPER_API_KEY,\n",
    "    'Content-Type': 'application/json'\n",
    "    }\n",
    "    url = \"https://google.serper.dev/search\"\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload) \n",
    "    data = json.loads(response.text)\n",
    "    \n",
    "    # Extract URLs from the \"organic\" search results\n",
    "    urls = [entry[\"link\"] for entry in data.get(\"organic\", [])]\n",
    "\n",
    "    return urls\n",
    "\n",
    "\n",
    "def get_interpretations_list(test_name,urls,chat,tokenizer,max_tokens):\n",
    "    \n",
    "    extracted_texts = []\n",
    "    for url in urls:\n",
    "            content = scrape_and_extract(url)\n",
    "            if content:\n",
    "                cleaned_text = clean_text(content)\n",
    "                extracted_texts.append(cleaned_text)\n",
    "\n",
    "    web_content = \"\\n\\n\".join(extracted_texts)\n",
    "    web_content_chunks = chunk_text(web_content,tokenizer,max_tokens)\n",
    "\n",
    "    responses = []\n",
    "    for i in range(len(web_content_chunks)):\n",
    "        messages = [\n",
    "            SystemMessage(content=\"You are a medical expert providing the relavent content from the given one.\"),\n",
    "            HumanMessage(content=f\"\"\"Based on the following information:\\n\\n{web_content_chunks[i]}\\n\\n extract the information\n",
    "        that can help in interpreting the medical report related to {test_name} (test). Don't type \n",
    "        anything else. Just provide the relavent information from the content nothing else, if there\n",
    "        is nothing relevant then just response with there is nothing helpful but dont type anything from your knowledge.\"\"\")\n",
    "        ]\n",
    "        response = chat(messages)\n",
    "        response = remove_tags(response.content)\n",
    "        responses.append(response)\n",
    "        \n",
    "    return responses\n",
    "\n",
    "def summarize_web_content(list_of_interpretations, test_name,chat):\n",
    "    \"\"\"Summarize the interpretations.\"\"\"\n",
    "    # Join the interpretations into a single string\n",
    "    interpretations = \"\".join(list_of_interpretations)\n",
    "    chain = chat | StrOutputParser()\n",
    "\n",
    "    prompt = f\"\"\"You are a medical expert. Summarize the provided content in a maximum of 1000 words to aid \n",
    "    in interpreting the medical report related to {test_name}. Ensure the summary remains within the word \n",
    "    limit while retaining key insights.\n",
    "\n",
    "    Content: {interpretations}\"\"\"\n",
    "\n",
    "    response = chain.invoke(prompt)\n",
    "    response = remove_tags(response)\n",
    "    return response\n",
    "\n",
    "\n",
    "def generate_refined_prompt(query,type,disease,chat):\n",
    "    \n",
    "    # Construct prompt\n",
    "    prompt = f\"\"\"You are an expert doctor. I have provided the test type, \n",
    "    the suspected disease (if mentioned by the patient), and the lab report. Since the lab report \n",
    "    primarily consists of numerical values, retrieving relevant context from my RAG system is challenging.\n",
    "    Your task is to generate a maximum of 200-300 words textual summary that best represents this report,\n",
    "    incorporating key abnormalities or notable findings. Provide 2 descriptions which are inside the     \n",
    "    <p>*</p> tag (don't use any other mode for separating them). This summary will be used to fetch the \n",
    "    most relevant medical context from my RAG, which, along with the report, will help the LLM provide an \n",
    "    accurate interpretation.\n",
    "\n",
    "    For your information so that you can write the desrciption in a familiar way, the data i have scrapped \n",
    "    is from Testing.com, medlinplus.com and some books.\n",
    "    Don't write anything else, other than the relavant interpretation.\n",
    "    :\n",
    "    \n",
    "    Type: {type}\n",
    "    Diesease: {disease}\n",
    "    Report: {query}\n",
    "        \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    chain = chat | StrOutputParser()\n",
    "    \n",
    "    response = chain.invoke(prompt)\n",
    "    response = remove_tags(response)\n",
    "    response = only_p_tags(response)\n",
    "    return response # returns the list of 2 description\n",
    "\n",
    "\n",
    "def discard_irrelevant_context(test_name,normal_ranges,retrieved_context,report,web_content,chat):\n",
    "    \n",
    "    # Construct prompt\n",
    "    prompt = f\"\"\"You are an expert doctor. Your task is to extract only the most relevant \n",
    "    information from the provided medical context and discard anything unrelated.  \n",
    "\n",
    "### Given Information:\n",
    "- **Test Type:** {test_name}  \n",
    "- **Medical Report:** {report}  \n",
    "- **Normal Ranges:** {normal_ranges}  \n",
    "- **Context:** {retrieved_context} \\n {web_content}  \n",
    "\n",
    "### Instructions:\n",
    "- Read the retrieved context carefully.  \n",
    "- Identify the information that is directly relevant to the test {test_name} and the provided ranges (only\n",
    " consider the provided ranges if the normal ranges are not present in the test report, otherwise consider the provided ones).  \n",
    "- Extract only the relevant paragraphs and discard anything that is not directly related.  \n",
    "- Ensure that the extracted content provides useful insights about the given test.  \n",
    "\n",
    "### Output Format:\n",
    "Return the **filtered context** as clean paragraphs that are relevant to {test_name}. Do not include any unrelated information, just provide the paragraphs nothing else.  \n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    chain = chat | StrOutputParser()\n",
    "    \n",
    "    response = chain.invoke(prompt)\n",
    "    response = remove_tags(response)\n",
    "    return response # final paragraphs\n",
    "\n",
    "\n",
    "def generate_final_output(report,type,disease,generated_text,context,chat):\n",
    "    \n",
    "    \n",
    "    # Construct prompt\n",
    "    prompt = f\"\"\"You are a expert doctor. You have to interpret the medical lab report of the patient. I have provided \n",
    "    you the lab report, the test type, the disease which the patient thinks he is suffereing from and some context which may assist you in interpreting the report.\n",
    "    Interpret the report in layman understandable form in just 2 lines, not more than that and donot write anything else other than the interpretation. If you think that\n",
    "    the disease he thinks he is suffering from do not match the report, you can mention that as well and recommend the possible diseases.In case the Context is not benificial,\n",
    "    you can ignore it and answer from your own knowledge. Also score your answer out of 10, but just the number in the markdown form, nothing else. The answer should not be more than 2 to 3 lines.\n",
    "    And after that also tell whether the provided context was helpful in interpretation or not, and provide the part which was helpful (it can be detailed)\n",
    "    also rate the helpfullness.\n",
    "    :\n",
    "        \n",
    "    Context: {context}\n",
    "    Type: {type}\n",
    "    Disease: {disease}\n",
    "    Report: {report}\n",
    "    Random Context (it can be wrong): {generated_text}\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    chain = chat | StrOutputParser()\n",
    "    \n",
    "    response = chain.invoke(prompt)\n",
    "    response = remove_tags(response)\n",
    "    return response\n",
    "\n",
    "\n",
    "def web_search(test_name,chat,SERPER_API_KEY,tokenizer,max_tokens):\n",
    "    urlss = get_URLs(test_name,SERPER_API_KEY)\n",
    "    interpretation = get_interpretations_list(test_name,urlss,chat,tokenizer,max_tokens)\n",
    "    texttt = summarize_web_content(interpretation, test_name,chat)\n",
    "    print(\"web search completed\")\n",
    "    return texttt\n",
    "\n",
    "def VDB_search(test_name,report,chat,disease,embedding_model,index,top_k=5):\n",
    "    generated_text = generate_refined_prompt(report,test_name,disease,chat)\n",
    "    retrieved_content = retrieve_context(generated_text,embedding_model,index,top_k)\n",
    "    unique_content = get_unique_content_only(retrieved_content)\n",
    "    print(\"VDB search completed\")\n",
    "    return unique_content,generated_text\n",
    "    \n",
    "def final_output(test_name,unique_content,report,texttt,disease,generated_text,chat,normal_ranges):\n",
    "    context = discard_irrelevant_context(test_name,normal_ranges,unique_content,report,texttt,chat)\n",
    "    response = generate_final_output(report,test_name,disease,generated_text,context,chat)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_name = \"CBC\"\n",
    "disease = \"Dengue\"\n",
    "\n",
    "report = \"\"\"Hemoglobin (Hb)\t12.5 g/dL\t13.0 - 17.0 g/dL (M) / 12.0 - 15.0 g/dL (F)\n",
    "Hematocrit (Hct)\t38%\t38 - 50% (M) / 36 - 44% (F)\n",
    "White Blood Cell (WBC) Count\t3,000 cells/µL\t4,000 - 11,000 cells/µL\n",
    "Neutrophils\t35%\t40 - 75%\n",
    "Lymphocytes\t55%\t20 - 40%\n",
    "Platelet Count\t75,000 cells/µL\t150,000 - 450,000 cells/µL\n",
    "Mean Platelet Volume (MPV)\t10.5 fL\t7.5 - 12.0 fL\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"deepseek-r1-distill-llama-70b\"\n",
    "# model_name = \"llama-3.3-70b-versatile\"\n",
    "# model_name = \"qwen-2.5-32b\"\n",
    "\n",
    "\n",
    "chat = ChatGroq(\n",
    "api_key = GROQ_API_KEY,\n",
    "model_name = model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = \"deepseek-r1-distill-llama-70b\"\n",
    "\n",
    "chat2 = ChatGroq(\n",
    "api_key = GROQ_API_KEY,\n",
    "model_name = model2\n",
    ")   \n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")  # Adjust for your LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omarb\\AppData\\Local\\Temp\\ipykernel_7220\\3626611080.py:129: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = chat(messages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VDB search completed\n",
      "web search completed\n",
      "\n",
      "\n",
      "The CBC report shows low platelets, white blood cells, and a shift in lymphocytes, consistent with dengue fever. These findings align with typical dengue symptoms.  \n",
      "Score: 10  \n",
      "\n",
      "Context Helpfulness: The context provided was very helpful as it correctly identified the abnormalities (leukopenia, thrombocytopenia, lymphocytosis) and linked them to dengue fever.  \n",
      "Helpfulness Score: 9/10\n"
     ]
    }
   ],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        # Run web search and vector database functions in parallel\n",
    "        web_search_content = executor.submit(web_search, test_name, chat, SERPER_API_KEY,tokenizer,max_tokens = 4500)\n",
    "        VDB_content = executor.submit(VDB_search,test_name, report, chat, disease, embedding_model, index, top_k=5)\n",
    "        \n",
    "        try:\n",
    "            # Get the results\n",
    "            web_results = web_search_content.result()\n",
    "            vector_results, generated_text = VDB_content.result()\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "        \n",
    "        # Pass the results to discard_irrelevant_content\n",
    "        final_results = final_output(test_name, vector_results, report, web_results, disease, generated_text,chat, normal_ranges=None)\n",
    "        print (final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory = ConversationBufferMemory()\n",
    "# conversation = ConversationChain(\n",
    "#     llm=chat2,\n",
    "#     memory=memory\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22.6 / 15.0 / 18.2\n",
    "# 10\n",
    "# 4.5\n",
    "# 4.4\n",
    "# 2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_name = \" Dengue Hemorrhagic Fever \"\n",
    "# disease = \"dengue\"\n",
    "\n",
    "# report = '''Characteristic\tDF¹ (%)\tDHF¹ (%)\tN\tp-value²\n",
    "# Demographics\t\t\t\t\n",
    "# Age (median ± interquartile range)\t26.0 ± 19.0\t24.5 ± 18.0\t201\t0.905\n",
    "# Gender\t\t\t\t\n",
    "# Male\t99 (61.5)\t30 (75.0)\t201\t0.077\n",
    "# Female\t62 (38.5)\t10 (25.0)\t\t\n",
    "# Clinical Presentation\t\t\t\t\n",
    "# Fever\t159/161 (98.8)\t39/39 (100.0)\t200\t0.647\n",
    "# Nausea and/or vomiting\t93/161 (57.8)\t27/40 (67.5)\t201\t0.173\n",
    "# Rash\t44/161 (27.3)\t31/40 (77.5)\t201\t<0.001\n",
    "# Abdominal Pain\t6/86 (7.0)\t1/11 (9.1)\t97\t0.582\n",
    "# Diarrhea\t26/161 (16.2)\t5/40 (12.5)\t201\t0.384\n",
    "# Myalgia\t46/161 (28.6)\t6/40 (15.0)\t201\t0.056\n",
    "# Headache\t21/161 (13.0)\t2/40 (5.0)\t201\t0.120\n",
    "# Cough\t22/161 (13.7)\t1/40 (2.5)\t201\t0.033\n",
    "# Hemorrhage\t6/161 (3.7)\t29/40 (72.5)\t201\t<0.001\n",
    "# Temperature (median)\t38.00 ± 2.00\t37.00 ± 1.00\t177\t0.014\n",
    "# Laboratory Findings\t\t\t\t\n",
    "# Thrombocytopenia at presentation\t116/151 (76.8)\t36/40 (90.0)\t191\t0.047\n",
    "# Received platelet transfusion\t25/90 (27.8)\t13/32 (40.6)\t122\t0.131\n",
    "# Low Hemoglobin\t16/137 (11.7)\t8/37 (21.6)\t174\t0.102\n",
    "# Hematocrit level on admission (median)\t39.50 ± 6.75\t40.40 ± 8.80\t167\t0.607\n",
    "# Leukopenia\t64/141 (45.4)\t9/37 (24.3)\t178\t0.015\n",
    "# Neutropenia\t35/133 (26.3)\t16/34 (47.1)\t167\t0.018\n",
    "# Lymphocytosis\t30/132 (22.7)\t7/33 (21.2)\t165\t0.529\n",
    "# Monocytosis\t32/122 (26.2)\t19/33 (57.6)\t155\t0.001\n",
    "# Raised ALT\t63/110 (57.3)\t27/32 (84.4)\t142\t0.004\n",
    "# Raised AST\t68/79 (86.1)\t25/26 (96.2)\t105\t0.147'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report = \"\"\"Complete Blood Count (CBC) Report\n",
    "# Test\tResult\tReference Range\tUnits\tFlag\n",
    "# White Blood Cell Count (WBC)\t7.5\t4.0 - 11.0\tx10³/μL\tNormal\n",
    "# Red Blood Cell Count (RBC)\t3\t4.5 - 5.9\tx10⁶/μL\tAbnormal\n",
    "# Hemoglobin (Hgb)\t15.0\t13.5 - 17.5\tg/dL\tNormal\n",
    "# Hematocrit (Hct)\t45\t40 - 52\t%\tNormal\n",
    "# Mean Corpuscular Volume (MCV)\t88\t80 - 100\tfL\tNormal\n",
    "# Mean Corpuscular Hemoglobin (MCH)\t29\t27 - 34\tpg\tNormal\n",
    "# Mean Corpuscular Hemoglobin Concentration (MCHC)\t34\t32 - 36\tg/dL\tNormal\n",
    "# Red Cell Distribution Width (RDW)\t13.5\t11.5 - 14.5\t%\tNormal\n",
    "# Platelet Count\t250\t150 - 450\tx10³/μL\tNormal\n",
    "# Neutrophils\t35\t40 - 70\t%\tAbnormal\n",
    "# Lymphocytes\t10\t20 - 40\t%\tAbnormal\n",
    "# Monocytes\t6\t2 - 10\t%\tNormal\n",
    "# Eosinophils\t3\t1 - 4\t%\tNormal\n",
    "# Basophils\t1\t0 - 2\t%\tNormal\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
